{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matrix_class import *\n",
    "from cluster_class import *\n",
    "from degreelist_class import *\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_matrix_file = \"../data/testing_data/fake_cluster_dream.txt\"\n",
    "testing_cluster_file = \"../data/testing_data/fake_cluster.txt\"\n",
    "\n",
    "dream3_matrix_file = \"../data/networks/DREAM_files/dream_3.txt\"\n",
    "dream3_cluster_file = \"../data/results/DREAM-3-cc/d3_5_100.json-cluster.json\" \n",
    "\n",
    "dream3_clusters_dict = {}\n",
    "# convert actual cluster file to a dictionary!!\n",
    "with open(dream3_cluster_file,\"r\") as cluster_dict_file:\n",
    "    dream3_clusters_dict = json.load(cluster_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_matrix = ProteinMatrix(testing_matrix_file)\n",
    "testing_clusters = AllClusters(testing_cluster_file)\n",
    "testing_degreelist = DegreeList(testing_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = AllClusters(protein_to_cluster_dict=dream3_clusters_dict)\n",
    "matrix = ProteinMatrix(dream3_matrix_file)\n",
    "degreelist = DegreeList(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clusters_and_proteins_together(matrix: ProteinMatrix, clusters: AllClusters, degreelist: DegreeList, cluster_ratio: float = .5, cluster_constant: int = 0, protein_ratio: float = .5, protein_constant: int = 0, min_components_that_protein_connects: int = -1, max_degree: int = 500) -> list() and dict():\n",
    "    \"\"\"\n",
    "    function is a version of find_clusters_that_match_criteria, that, once it finds the cluster, finds corresponding proteins at the same time so that the submatrix doesn't need to be reconstructed\n",
    "\n",
    "    Parameters: \n",
    "        matrix - a ProteinMatrix of all protein interactions\n",
    "        clusters - an AllClusters containing proteins grouped into clusters\n",
    "        cluster_ratio and cluster_constant - used together to determine which clusters qualify, with the output of the function being cluster_ratio * input + cluster_constant\n",
    "        TODO: remaining parameters\n",
    "    Purpose:    determines clusters that are mostly highly connected, then \n",
    "                determines which proteins that, when added to the cluster, will \n",
    "                increase it's connectedness\n",
    "    Returns:    a list containing the numbers of the clusters that qualify, and \n",
    "                a dictionary linking each cluster, to a list of the qualifying \n",
    "                proteins\n",
    "    \"\"\"\n",
    "    \n",
    "    cluster_nums_that_qualify = list()\n",
    "    qualifying_proteins_dict = dict()\n",
    "\n",
    "    for cluster_num in clusters.get_all_clusters():\n",
    "        # create a submatrix out of the proteins in the cluster\n",
    "        submatrix = SubMatrix(clusters.get_cluster_proteins(cluster_num), matrix)\n",
    "        num_components, labels = submatrix.get_num_components_and_labels()\n",
    "        # print(f\"num components is {num_components}. num proteins is {len(submatrix.get_list_of_proteins())}\")\n",
    "        if num_components < cluster_ratio * len(submatrix.get_list_of_proteins()) + cluster_constant:\n",
    "\n",
    "            # add cluster to list showing that it qualifies, \n",
    "            cluster_nums_that_qualify.append(cluster_num)\n",
    "            # then do analysis on the cluster\n",
    "            qualifying_proteins_dict[cluster_num] = qualifying_proteins_using_submatrix(cluster_num, submatrix, clusters, degreelist, ratio=protein_ratio, constant=protein_constant, min_components_that_protein_connects=min_components_that_protein_connects, max_degree=max_degree)\n",
    "\n",
    "\n",
    "    return cluster_nums_that_qualify, qualifying_proteins_dict\n",
    "\n",
    "\n",
    "def qualifying_proteins_using_submatrix(cluster_num: int, submatrix: SubMatrix, clusters: AllClusters, degreelist: DegreeList, ratio: float = .5, constant: int = 0, min_components_that_protein_connects: int = -1, max_degree: int = 500) -> list():\n",
    "    \"\"\"\n",
    "    TODO : a revised version of the find_proteins_that_match_criteria function that takes in a submatrix as a parameter, and therefore doesn't need to construct one. \n",
    "    \"\"\"\n",
    "    if (min_components_that_protein_connects == -1):\n",
    "            min_components_that_protein_connects = constant + ratio * len(clusters.get_cluster_proteins(cluster_num))\n",
    "        \n",
    "    num_components, labels = submatrix.get_num_components_and_labels()\n",
    "\n",
    "    ### POPULATE COMPONENT DICTIONARY ###\n",
    "    component_dictionary = dict() # protein : component_num\n",
    "    j = 0\n",
    "    for array in [(np.array(submatrix.get_list_of_proteins())[np.nonzero(labels == i)]) for i in range(num_components)]:\n",
    "        for protein in array:\n",
    "            component_dictionary[protein] = j\n",
    "        j += 1\n",
    "    \n",
    "    ## FIND CONNECTED PROTEINS AND DETERMINE IF THEY QUALIFY \n",
    "    qualifying_proteins = list()\n",
    "\n",
    "    for protein in (degreelist.get_list_of_proteins_sorted_by_degree()):   \n",
    "        num_edges, which_proteins = degreelist.determine_num_edges_to_cluster(protein, clusters.get_cluster_proteins(cluster_num), also_return_which_proteins=True)\n",
    "                \n",
    "        if (num_edges >= min_components_that_protein_connects):\n",
    "            set_of_components_that_protein_connects = degreelist.which_components_of_a_cluster_would_a_protein_connect(protein, clusters.get_cluster_proteins(cluster_num), component_dictionary, connected_proteins_within_cluster=which_proteins)\n",
    "\n",
    "            if len(set_of_components_that_protein_connects) >= min_components_that_protein_connects:\n",
    "                qualifying_proteins.append(protein)\n",
    "\n",
    "    return qualifying_proteins\n",
    "\n",
    "\n",
    "def pick_ratio(num_clusters: int):\n",
    "    \"\"\"\n",
    "    will determine an approximate ratio to start with based on the total number of clusters\n",
    "    \"\"\"\n",
    "    if (num_clusters > 1000):\n",
    "        return .5\n",
    "    elif num_clusters > 500:\n",
    "        return .7\n",
    "    elif num_clusters > 200:\n",
    "        return .9\n",
    "    elif num_clusters > 100:\n",
    "        return .925\n",
    "    elif num_clusters > 50:\n",
    "        return .995\n",
    "    else: \n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualifying_clusters, qualifying_proteins = find_clusters_and_proteins_together(matrix, clusters, degreelist, cluster_ratio=pick_ratio(clusters.get_num_clusters()), protein_ratio=.05, protein_constant=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 29, 30, 36, 49, 73, 75, 99, 152, 161, 164, 174, 185]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{qualifying_clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{25: ['AKT1', 'SRC'], 29: ['CDK1', 'PRKACA'], 30: [], 36: [], 49: ['EGFR', 'MAPK1', 'SRC'], 73: ['TP53', 'MAPK1', 'PRKCA', 'SRC'], 75: [], 99: [], 152: ['CSNK2A1', 'PRKACA'], 161: ['CSNK2A1'], 164: ['BCL2', 'MAPK8', 'MAPK1'], 174: [], 185: ['TSC1', 'IKBKB']}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{qualifying_proteins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! please specify a [csv_filename] or a [protein_to_cluster_dict] not found.\n"
     ]
    }
   ],
   "source": [
    "def create_new_clusters(clusters_to_qualifying_proteins: dict(), csv_filename: str = \"\", protein_to_cluster_dict: dict() = {}, original_clusters: AllClusters = AllClusters(), ) -> AllClusters:\n",
    "    \"\"\"\n",
    "    csv_filename: str = \"\", protein_to_cluster_dict: dict() ={}, original_clusters: AllClusters = AllClusters(), are all different ways to pass in info to make new clusters (and you should choose one of them). Please note, that if you use Original Clusters, the original clusters will be modified to include the new qualifying proteins\n",
    "    \"\"\"\n",
    "    modified_clusters = AllClusters()\n",
    "    \n",
    "    if csv_filename != \"\":\n",
    "        modified_clusters = AllClusters(csv_filename=csv_filename)\n",
    "    elif protein_to_cluster_dict: # dictionary not empty\n",
    "        modified_clusters = AllClusters(protein_to_cluster_dict=protein_to_cluster_dict)\n",
    "    else:\n",
    "        modified_clusters = original_clusters\n",
    "    \n",
    "    for key in clusters_to_qualifying_proteins:\n",
    "        if clusters_to_qualifying_proteins[key]: # will return true if this cluster has qualifying proteins (list not empty)\n",
    "            for protein in clusters_to_qualifying_proteins[key]:\n",
    "                modified_clusters.add_protein_to_cluster(protein, key)\n",
    "    return modified_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! please specify a [csv_filename] or a [protein_to_cluster_dict] not found.\n"
     ]
    }
   ],
   "source": [
    "new_clusters = create_new_clusters(qualifying_proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AllClusters has 199 clusters (use the print_all method to see them)\n"
     ]
    }
   ],
   "source": [
    "print(new_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TRPV3', 'KHDRBS2', 'PDZD2', 'TP73', 'TICAM1', 'PHKG1', 'KITLG', 'TBK1', 'RAC1', 'RUSC1', 'CBS', 'MAPK11', 'MAP2K6', 'PAWR', 'CDK10', 'SPTAN1', 'TRPV3', 'KHDRBS2', 'PDZD2', 'TP73', 'TICAM1', 'PHKG1', 'KITLG', 'TBK1', 'RAC1', 'RUSC1', 'CBS', 'MAPK11', 'MAP2K6', 'PAWR', 'CDK10', 'SPTAN1', 'AKT1', 'SRC', 'AKT1', 'SRC', 'AKT1', 'SRC', 'AKT1', 'SRC', 'AKT1', 'SRC', 'AKT1', 'SRC', 'AKT1', 'SRC', 'AKT1', 'SRC']\n",
      "['TRPV3', 'KHDRBS2', 'PDZD2', 'TP73', 'TICAM1', 'PHKG1', 'KITLG', 'TBK1', 'RAC1', 'RUSC1', 'CBS', 'MAPK11', 'MAP2K6', 'PAWR', 'CDK10', 'SPTAN1', 'TRPV3', 'KHDRBS2', 'PDZD2', 'TP73', 'TICAM1', 'PHKG1', 'KITLG', 'TBK1', 'RAC1', 'RUSC1', 'CBS', 'MAPK11', 'MAP2K6', 'PAWR', 'CDK10', 'SPTAN1', 'AKT1', 'SRC', 'AKT1', 'SRC', 'AKT1', 'SRC', 'AKT1', 'SRC', 'AKT1', 'SRC', 'AKT1', 'SRC', 'AKT1', 'SRC', 'AKT1', 'SRC']\n"
     ]
    }
   ],
   "source": [
    "print(clusters.get_cluster_proteins(25))\n",
    "print(new_clusters.get_cluster_proteins(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PPP1R15A', 'MMP14', 'BCL2L12', 'PTX3', 'HLA-C', 'KAT8', 'EIF2S2', 'RASSF7', 'AKT2', 'PRKAA2', 'PIP5K1A', 'RAB11A', 'CASP3', 'PPP1R15A', 'MMP14', 'BCL2L12', 'PTX3', 'HLA-C', 'KAT8', 'EIF2S2', 'RASSF7', 'AKT2', 'PRKAA2', 'PIP5K1A', 'RAB11A', 'CASP3']\n",
      "['PPP1R15A', 'MMP14', 'BCL2L12', 'PTX3', 'HLA-C', 'KAT8', 'EIF2S2', 'RASSF7', 'AKT2', 'PRKAA2', 'PIP5K1A', 'RAB11A', 'CASP3', 'PPP1R15A', 'MMP14', 'BCL2L12', 'PTX3', 'HLA-C', 'KAT8', 'EIF2S2', 'RASSF7', 'AKT2', 'PRKAA2', 'PIP5K1A', 'RAB11A', 'CASP3']\n"
     ]
    }
   ],
   "source": [
    "print(clusters.get_cluster_proteins(185))\n",
    "print(new_clusters.get_cluster_proteins(185))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('diamonds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e113e58b579a48e5732235004b32d872074e11125058c2d5e4f294336344a2ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
